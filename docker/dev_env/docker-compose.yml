version: '3.5'
volumes:
  zookeeper-data:
    name: ortelius_zookeeper_data
  zookeeper-log:
    name: ortelius_zookeeper_logs
  kafka-data:
    name: ortelius_kafka
  redis-data:
    name: ortelius_redis
  mysql-data:
    name: ortelius_mysql
  avalanche-data:
    name: ortelius_avalanche
  avalanche-ipcs:
    name: ortelius_avalanche_ipcs
networks:
  default:
    name: ortelius_services
services:
  mysql:
    image: mysql:8.0
    volumes:
      - mysql-data:/var/lib/mysql
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: ortelius_dev
    restart: on-failure
  migrate:
    image: migrate/migrate:v4.11.0
    volumes:
      - ../../services/db/migrations:/migrations
    depends_on:
      - mysql
    entrypoint: ["/bin/sh"]
    command: |
      -c 'while ! migrate -path=/migrations/ -database "mysql://root:password@tcp(mysql:3306)/ortelius_dev" up; do
        sleep 1
      done'
    restart: on-failure
  redis:
    image: "redis:6.0.5-alpine3.12"
    command: redis-server
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/var/lib/redis
    restart: on-failure
  avalanche:
    image: "avaplatform/avalanchego:a7890896"
    command: [
      "./build/avalanchego",
      "-db-dir=/var/lib/avalanche",
      "-log-level=info",
      "-http-host=0.0.0.0",
      "-ipcs-chain-ids=11111111111111111111111111111111LpoYY,jnUjZSRt16TcRnZzmh5aMhavwVHz3zBrSN8GfFMTQkzUnoBxC",
    ]
    ports:
      - "9650:9650"
    volumes:
      - avalanche-data:/var/lib/avalanche
      - avalanche-ipcs:/tmp
    restart: always
  zookeeper:
    image: confluentinc/cp-zookeeper:5.0.0
    ports:
      - 2181
    environment:
      - ZOOKEEPER_SERVER_ID=1
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_SERVERS=zookeeper:4182:5181
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data/
      - zookeeper-log:/var/lib/zookeeper/log/
    healthcheck:
      test: /bin/sh -c '[ \"imok\" = \"$$(echo ruok | nc -w 1 127.0.0.1 2181)\" ]' || exit 1
      interval: 1m
    restart: on-failure
  kafka:
    image: confluentinc/cp-kafka:5.0.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    volumes:
      - kafka-data:/var/lib/kafka/data/
    restart: on-failure
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://127.0.0.1:29092

      KAFKA_BROKER_ID: 1
      CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_HEAP_OPTS: -Xms256M -Xmx256M -verbose:gc
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_NUM_PARTITIONS: 8
      KAFKA_OFFSETS_RETENTION_MINUTES: 446400

      # Disable replication and lower thread count
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1

      KAFKA_NUM_RECOVERY_THREADS_PER_DATA_DIR: 1
      KAFKA_NUM_NETWORK_THREADS: 3
      KAFKA_NUM_IO_THREADS: 3

      # Set retention policies
      KAFKA_LOG_CLEANUP_POLICY: compact
      KAFKA_LOG_RETENTION_BYTES: -1
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_RETENTION_HOURS: -1
      KAFKA_LOG_ROLL_HOURS: 24
      KAFKA_LOG_SEGMENT_BYTES: 1048576
      KAFKA_LOG_SEGMENT_DELETE_DELAY_MS: 60000
